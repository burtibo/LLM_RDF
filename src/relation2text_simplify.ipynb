{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: C:\\Users\\31615\\Desktop\\thesis\\triples\n"
     ]
    }
   ],
   "source": [
    "# Set the directory\n",
    "os.chdir(r\"C:\\Users\\...\")\n",
    "\n",
    "# Confirm the current directory\n",
    "print(\"Current Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              relation  \\\n",
      "0    /soccer/football_team/current_roster./soccer/f...   \n",
      "1                                 /music/artist/origin   \n",
      "2    /ice_hockey/hockey_team/current_roster./sports...   \n",
      "3    /food/food/nutrients./food/nutrition_fact/nutr...   \n",
      "4              /film/actor/film./film/performance/film   \n",
      "..                                                 ...   \n",
      "232             /base/biblioness/bibs_location/country   \n",
      "233  /user/ktrueman/default_domain/international_or...   \n",
      "234  /music/performance_role/track_performances./mu...   \n",
      "235  /olympics/olympic_games/medals_awarded./olympi...   \n",
      "236  /base/saturdaynightlive/snl_cast_member/season...   \n",
      "\n",
      "                                                  text  cluster  \\\n",
      "0    soccer football team current roster. soccer fo...       18   \n",
      "1                                  music artist origin       11   \n",
      "2    ice hockey hockey team current roster. sports ...       18   \n",
      "3    food food nutrients. food nutrition fact nutrient       10   \n",
      "4               film actor film. film performance film        1   \n",
      "..                                                 ...      ...   \n",
      "232              base biblioness bibs location country        7   \n",
      "233  user ktrueman default domain international org...       19   \n",
      "234  music performance role track performances. mus...       16   \n",
      "235  olympics olympic games medals awarded. olympic...       13   \n",
      "236  base saturdaynightlive snl cast member seasons...       14   \n",
      "\n",
      "                                      cluster_words  \n",
      "0          roster, sports, position, football, team  \n",
      "1         music, artist, genre, contribution, track  \n",
      "2          roster, sports, position, football, team  \n",
      "3    government, administrative, base, held, county  \n",
      "4             film, by, performance, release, actor  \n",
      "..                                              ...  \n",
      "232  country, location, capital, language, division  \n",
      "233     user, member, olympic, organization, sports  \n",
      "234     music, group, role, membership, performance  \n",
      "235      olympics, olympic, medal, country, athlete  \n",
      "236              base, current, event, of, location  \n",
      "\n",
      "[237 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load relation-to-text mappings\n",
    "relation2text = pd.read_csv(\"data/FB15k237/relation2text.txt\", sep=\"\\t\", header=None, names=[\"relation\", \"text\"])\n",
    "\n",
    "# Vectorize relation descriptions using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "X = vectorizer.fit_transform(relation2text['text'])\n",
    "\n",
    "# Cluster relations using k-means\n",
    "n_clusters = 20  # Adjust the number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "relation2text['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Extract representative words for each cluster\n",
    "terms = np.array(vectorizer.get_feature_names_out())\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "top_n = 5  # Number of top words to extract\n",
    "\n",
    "# Create a mapping of clusters to their representative words\n",
    "cluster_words = {\n",
    "    f\"cluster_{i}\": terms[np.argsort(-cluster_centers[i])[:top_n]].tolist()\n",
    "    for i in range(n_clusters)\n",
    "}\n",
    "\n",
    "# Add representative words to the DataFrame\n",
    "relation2text['cluster_words'] = relation2text['cluster'].map(\n",
    "    lambda x: \", \".join(cluster_words[f\"cluster_{x}\"])\n",
    ")\n",
    "\n",
    "# Save the result\n",
    "relation2text[['relation', 'text', 'cluster', 'cluster_words']].to_csv(\"data/FB15k237/simplified_relation2text.csv\", index=False)\n",
    "\n",
    "# Display the mapping\n",
    "print(relation2text[['relation', 'text', 'cluster', 'cluster_words']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Mapping:\n",
      "     cluster_number                                      cluster_words\n",
      "0                18           roster, sports, position, football, team\n",
      "1                11          music, artist, genre, contribution, track\n",
      "3                10     government, administrative, base, held, county\n",
      "4                 1              film, by, performance, release, actor\n",
      "5                15                  award, honor, awards, for, winner\n",
      "7                 2          measurement, unit, currency, money, value\n",
      "8                 8                  people, person, place, of, tenure\n",
      "11               14                 base, current, event, of, location\n",
      "14               17  location, statistical, region, relationship, p...\n",
      "15                0           tv, program, producer, regular, personal\n",
      "18                5               category, award, of, actor, producer\n",
      "19               19        user, member, olympic, organization, sports\n",
      "20                9  education, educational, institution, degree, f...\n",
      "26                7     country, location, capital, language, division\n",
      "29               12               sports, team, draft, league, athlete\n",
      "32                6      organization, location, place, region, member\n",
      "44               13         olympics, olympic, medal, country, athlete\n",
      "64                3               people, of, marriage, spouse, person\n",
      "73                4          popstra, base, celebrity, dated, location\n",
      "105              16        music, group, role, membership, performance\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV with cluster words\n",
    "relation_clusters = pd.read_csv(\"data/FB15k237/simplified_relation2text.csv\")\n",
    "\n",
    "# Extract only the 'cluster' and 'cluster_words' columns\n",
    "cluster_mapping = relation_clusters[['cluster', 'cluster_words']].drop_duplicates()\n",
    "\n",
    "# Rename columns for clarity\n",
    "cluster_mapping.columns = ['cluster_number', 'cluster_words']\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "cluster_mapping.to_csv(\"data/FB15k237/clusters_description.csv\", index=False)\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(\"Cluster Mapping:\")\n",
    "print(cluster_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Cluster Mapping:\n",
      "     cluster_number                         cluster_word\n",
      "0                 5             roster, sports, position\n",
      "1                29                 artist, music, track\n",
      "3                20          county, celebrities, travel\n",
      "4                 1                film, by, performance\n",
      "5                10               award, category, honor\n",
      "6                21        government, held, legislative\n",
      "7                 2          measurement, unit, currency\n",
      "8                25                people, person, place\n",
      "10               24       administrative, division, area\n",
      "11               18                   base, location, of\n",
      "14                7        location, statistical, region\n",
      "15                0                   tv, program, genre\n",
      "19               19                user, member, olympic\n",
      "20                4           education, students, field\n",
      "21               26               business, value, money\n",
      "25                6             business, tenure, people\n",
      "27                3           phone, schemastaging, base\n",
      "29               17                  sports, team, draft\n",
      "30               27  institution, educational, education\n",
      "32               16        organization, location, place\n",
      "33               14              education, degree, with\n",
      "44                8             olympics, olympic, medal\n",
      "49               23             music, role, performance\n",
      "62                9                  music, genre, actor\n",
      "64               12                    people, of, actor\n",
      "73               13             popstra, base, celebrity\n",
      "78               22                tv, producer, regular\n",
      "84               11             people, marriage, spouse\n",
      "105              28             group, membership, music\n",
      "169              15                      event, base, of\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV with cluster words\n",
    "relation_clusters = pd.read_csv(\"data/FB15k237/simplified_relation2text.csv\")\n",
    "\n",
    "# Extract only the 'cluster' and 'cluster_words' columns\n",
    "cluster_mapping = relation_clusters[['cluster', 'cluster_words']].drop_duplicates()\n",
    "\n",
    "# Rename columns for clarity\n",
    "cluster_mapping.columns = ['cluster_number', 'cluster_word']\n",
    "\n",
    "# Make cluster words unique\n",
    "used_words = set()\n",
    "def ensure_unique(word):\n",
    "    if word in used_words:\n",
    "        return None  # Skip duplicates\n",
    "    used_words.add(word)\n",
    "    return word\n",
    "\n",
    "# Apply uniqueness constraint\n",
    "cluster_mapping['cluster_word'] = cluster_mapping['cluster_word'].apply(ensure_unique)\n",
    "\n",
    "# Drop rows where words could not be made unique\n",
    "cluster_mapping = cluster_mapping.dropna()\n",
    "\n",
    "# Save the result to a new CSV file\n",
    "cluster_mapping.to_csv(\"data/FB15k237/unique_clusters_description.csv\", index=False)\n",
    "\n",
    "# Display the new DataFrame\n",
    "print(\"Unique Cluster Mapping:\")\n",
    "print(cluster_mapping)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
